{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DV0vCmPtqjTy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c836e68d-49f0-47d4-9b12-af9272d57dc2"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2XI9uOPqnDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports here\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUdvDv8nqwor",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "380b78de-03b5-427d-dca9-8a95ad3f4296"
      },
      "source": [
        "!ls \"/content/drive/My Drive/DAtaset\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test  Train  Valid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4xFm7BesrOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = \"/content/drive/My Drive/DAtaset/\"\n",
        "train_dir = data_dir + '/Train'\n",
        "valid_dir = data_dir + '/Valid'\n",
        "test_dir = data_dir + '/Test'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crkEx-SOq41N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define transforms for the training, validation, and testing sets\n",
        "training_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                          transforms.RandomResizedCrop(224),\n",
        "                                          transforms.RandomHorizontalFlip(),\n",
        "                                          transforms.ToTensor(),\n",
        "                                          transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                                                               [0.229, 0.224, 0.225])])\n",
        "\n",
        "validation_transforms = transforms.Compose([transforms.Resize(256),\n",
        "                                            transforms.CenterCrop(224),\n",
        "                                            transforms.ToTensor(),\n",
        "                                            transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                                                                 [0.229, 0.224, 0.225])])\n",
        "\n",
        "testing_transforms = transforms.Compose([transforms.Resize(256),\n",
        "                                         transforms.CenterCrop(224),\n",
        "                                         transforms.ToTensor(),\n",
        "                                         transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                                                              [0.229, 0.224, 0.225])])\n",
        "\n",
        "# TODO: Load the datasets with ImageFolder\n",
        "training_dataset = datasets.ImageFolder(train_dir, transform=training_transforms)\n",
        "validation_dataset = datasets.ImageFolder(valid_dir, transform=validation_transforms)\n",
        "testing_dataset = datasets.ImageFolder(test_dir, transform=testing_transforms)\n",
        "\n",
        "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
        "train_loader = torch.utils.data.DataLoader(training_dataset, batch_size=64, shuffle=True)\n",
        "validate_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=32)\n",
        "test_loader = torch.utils.data.DataLoader(testing_dataset, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6blcHKEtQYF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "d1c34244-1638-40f0-9381-478000ad6df2"
      },
      "source": [
        "# Build and train your network\n",
        "# Transfer Learning\n",
        "model = models.vgg16(pretrained=True)\n",
        "model"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace)\n",
              "    (2): Dropout(p=0.5)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace)\n",
              "    (5): Dropout(p=0.5)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b37qF1eytcIT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Freeze pretrained model parameters to avoid backpropogating through them\n",
        "for parameter in model.parameters():\n",
        "    parameter.requires_grad = False\n",
        "\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "# Build custom classifier\n",
        "classifier = nn.Sequential(OrderedDict([('fc1', nn.Linear(25088, 5000)),\n",
        "                                        ('relu', nn.ReLU()),\n",
        "                                        ('drop', nn.Dropout(p=0.5)),\n",
        "                                        ('fc2', nn.Linear(5000, 2)),\n",
        "                                        ('output', nn.LogSoftmax(dim=1))]))\n",
        "\n",
        "model.classifier = classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PxA_PnEthGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function for the validation pass\n",
        "def validation(model, validateloader, criterion):\n",
        "    \n",
        "    val_loss = 0\n",
        "    accuracy = 0\n",
        "    \n",
        "    for images, labels in iter(validateloader):\n",
        "\n",
        "        images, labels = images.to('cuda'), labels.to('cuda')\n",
        "\n",
        "        output = model.forward(images)\n",
        "        val_loss += criterion(output, labels).item()\n",
        "\n",
        "        probabilities = torch.exp(output)\n",
        "        \n",
        "        equality = (labels.data == probabilities.max(dim=1)[1])\n",
        "        accuracy += equality.type(torch.FloatTensor).mean()\n",
        "    \n",
        "    return val_loss, accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMnWe3j5tjjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss function and gradient descent\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDrf_PUUtlxP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "92e6a1cd-e9c4-40a9-a2b9-10ec775f11b1"
      },
      "source": [
        "# Train the classifier\n",
        "\n",
        "\n",
        "\n",
        "def train_classifier():\n",
        "\n",
        "    \n",
        "\n",
        "        epochs = 13\n",
        "        steps = 0\n",
        "        print_every = 3\n",
        "\n",
        "        model.to('cuda')\n",
        "\n",
        "        for e in range(epochs):\n",
        "        \n",
        "            model.train()\n",
        "    \n",
        "            running_loss = 0\n",
        "    \n",
        "            for images, labels in iter(train_loader):\n",
        "        \n",
        "                steps += 1\n",
        "        \n",
        "                images, labels = images.to('cuda'), labels.to('cuda')\n",
        "        \n",
        "                optimizer.zero_grad()\n",
        "        \n",
        "                output = model.forward(images)\n",
        "                loss = criterion(output, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "        \n",
        "                running_loss += loss.item()\n",
        "        \n",
        "                if steps % print_every == 0:\n",
        "                \n",
        "                    model.eval()\n",
        "                \n",
        "                    # Turn off gradients for validation, saves memory and computations\n",
        "                    with torch.no_grad():\n",
        "                        validation_loss, accuracy = validation(model, validate_loader, criterion)\n",
        "            \n",
        "                    print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
        "                          \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\n",
        "                          \"Validation Loss: {:.3f}.. \".format(validation_loss/len(validate_loader)),\n",
        "                          \"Validation Accuracy: {:.3f}\".format(accuracy/len(validate_loader)))\n",
        "            \n",
        "                    running_loss = 0\n",
        "                    model.train()\n",
        "                    \n",
        "train_classifier()                    "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/13..  Training Loss: 7.004..  Validation Loss: 4.102..  Validation Accuracy: 0.510\n",
            "Epoch: 2/13..  Training Loss: 4.117..  Validation Loss: 3.077..  Validation Accuracy: 0.823\n",
            "Epoch: 3/13..  Training Loss: 2.971..  Validation Loss: 0.513..  Validation Accuracy: 0.733\n",
            "Epoch: 4/13..  Training Loss: 1.612..  Validation Loss: 1.219..  Validation Accuracy: 0.625\n",
            "Epoch: 5/13..  Training Loss: 0.844..  Validation Loss: 0.428..  Validation Accuracy: 0.896\n",
            "Epoch: 6/13..  Training Loss: 1.111..  Validation Loss: 0.740..  Validation Accuracy: 0.865\n",
            "Epoch: 7/13..  Training Loss: 0.852..  Validation Loss: 0.317..  Validation Accuracy: 0.917\n",
            "Epoch: 8/13..  Training Loss: 0.348..  Validation Loss: 0.499..  Validation Accuracy: 0.632\n",
            "Epoch: 9/13..  Training Loss: 0.795..  Validation Loss: 0.508..  Validation Accuracy: 0.642\n",
            "Epoch: 10/13..  Training Loss: 0.625..  Validation Loss: 0.262..  Validation Accuracy: 0.917\n",
            "Epoch: 11/13..  Training Loss: 0.388..  Validation Loss: 0.363..  Validation Accuracy: 0.896\n",
            "Epoch: 12/13..  Training Loss: 0.531..  Validation Loss: 0.272..  Validation Accuracy: 0.917\n",
            "Epoch: 13/13..  Training Loss: 0.305..  Validation Loss: 0.253..  Validation Accuracy: 0.938\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTjcJFwCtn9l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "23df638f-aa9f-48f9-9e71-206ee82dd0d1"
      },
      "source": [
        "def test_accuracy(model, test_loader):\n",
        "\n",
        "    # Do validation on the test set\n",
        "    model.eval()\n",
        "    model.to('cuda')\n",
        "\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        accuracy = 0\n",
        "    \n",
        "        for images, labels in iter(test_loader):\n",
        "    \n",
        "            images, labels = images.to('cuda'), labels.to('cuda')\n",
        "    \n",
        "            output = model.forward(images)\n",
        "\n",
        "            probabilities = torch.exp(output)\n",
        "        \n",
        "            equality = (labels.data == probabilities.max(dim=1)[1])\n",
        "        \n",
        "            accuracy += equality.type(torch.FloatTensor).mean()\n",
        "        \n",
        "        print(\"Test Accuracy: {}\".format(accuracy/len(test_loader)))    \n",
        "        \n",
        "        \n",
        "test_accuracy(model, test_loader)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.8999999761581421\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMFrQIupFRi0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}